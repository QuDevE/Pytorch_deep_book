{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfe8667",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "\n",
    "**Тенхзор - это структура данных, хранящая набор чисел, к которым можно обращаться по отдельности с помощью индекса, причем индексов может быть несколько.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84075201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "RND = 21\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# deterministic\n",
    "random.seed(RND)\n",
    "np.random.seed(RND)\n",
    "torch.manual_seed(RND)\n",
    "torch.cuda.manual_seed(RND)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# syntactic sugar\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863fa796",
   "metadata": {},
   "source": [
    "## 1.1 Pyton list VS Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669c7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1.0, 2.0, 3.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139de9f",
   "metadata": {},
   "source": [
    "К элементу этого списка можно обратиться по соответсвующим индексам, начиная с нулевого."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d8afc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34557913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad72e87",
   "metadata": {},
   "source": [
    "First tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d747223",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b84313a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb53aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca484b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9dd59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 3.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 3\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c9069",
   "metadata": {},
   "source": [
    "**Хотя внешне этот пример не слишком отличается от списка числовых объектов \"за кулисам\" все сильно отличается**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d5e56",
   "metadata": {},
   "source": [
    "### Что такое тензор?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca52cea",
   "metadata": {},
   "source": [
    "Списки и значения числовых значений Python представляют собой наборы объектов python, память под которые выделяется по отдельности.\n",
    "\n",
    "**Тензоры и массивы Numpy являются представлениями над (обычно) непрерывными блоками памяти, содержащими распакованные (unboxed) числовые типы данных С, а не объекты Python.**\n",
    "\n",
    "В нашем случае каждый элемент представляет собой 32-битное (4 байта) значения типа **float**. \n",
    "\n",
    "А это значит что для хранения 1 000 000 чисел типа float нам потребуется непрерывная область памяти в 4 000 000 байт + небольшое дополнительное место для метаданных. (размерности и числовой тип)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d813e8",
   "metadata": {},
   "source": [
    "### Доступ к тензорам по индексам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f5c821",
   "metadata": {},
   "source": [
    "Нотация диапазонного доступа по индексу в Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b85c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec7d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
      "[2, 3, 4, 5, 6, 7, 8]\n",
      "[0, 2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a[::-1])\n",
    "print(a[2:-1])\n",
    "print(a[::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d7c15",
   "metadata": {},
   "source": [
    "В Pytorch можно использовать ту же нотацию типов **с дополнительным плюсом** в виде возможности использовать в виде возможности использовать диапазонный доступ по индексу для каждого из измерений тензора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d88979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d635af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1., 2.], [3., 4.], [5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8998d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[4.],\n",
      "        [6.]])\n",
      "tensor([3., 5.])\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.],\n",
      "         [5., 6.]]])\n"
     ]
    }
   ],
   "source": [
    "print(a[1:])\n",
    "print(a[1:, :])\n",
    "print(a[1:, 1:])\n",
    "print(a[1:, 0])\n",
    "print(a[None]) # unsqueeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdfaa05",
   "metadata": {},
   "source": [
    "### Поименованные тензоры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67bf77f",
   "metadata": {},
   "source": [
    "Измерения (оси координат) тензоров обычно соответсвуют чему-то на подобие расположения пикселей или цветных канало. А это значит, что при доступе к тензору по индексам необходимо помнить порядок измерений и записывать индексы соответсвующим образом. Отслеживание того какое измерение содержит какие данные, может приводить к возникновению ошибок при преобразовании двнных через несколько тензоров.\n",
    "\n",
    "**Пример:**\n",
    "\n",
    "Дан трехмерный тензор, который необходимо преобразовать в оттенки серого. Ищем типичные весовые коэффициенты цветов для получения одного единого значения яркости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab6b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.rand(3, 5, 5) # форма [каналы, строки, столбцы]\n",
    "weights = torch.tensor([0.2116, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5898ae95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1752, 0.3951, 0.2414, 0.1056, 0.0685],\n",
       "          [0.0250, 0.2968, 0.0507, 0.9776, 0.4003],\n",
       "          [0.4270, 0.6945, 0.7185, 0.9751, 0.1906],\n",
       "          [0.4482, 0.5732, 0.0494, 0.4219, 0.8757],\n",
       "          [0.3706, 0.8420, 0.0281, 0.2398, 0.3721]],\n",
       "\n",
       "         [[0.9084, 0.0616, 0.3239, 0.4604, 0.3143],\n",
       "          [0.9487, 0.9416, 0.9318, 0.7542, 0.6262],\n",
       "          [0.7319, 0.7910, 0.1904, 0.8096, 0.1572],\n",
       "          [0.7041, 0.8846, 0.5671, 0.9018, 0.8865],\n",
       "          [0.9801, 0.7626, 0.1479, 0.9386, 0.4176]],\n",
       "\n",
       "         [[0.7609, 0.4928, 0.7538, 0.7552, 0.3135],\n",
       "          [0.7059, 0.3626, 0.2118, 0.6789, 0.9255],\n",
       "          [0.7055, 0.2060, 0.8446, 0.7541, 0.6133],\n",
       "          [0.0016, 0.5020, 0.8871, 0.9675, 0.5757],\n",
       "          [0.6287, 0.4687, 0.4433, 0.5450, 0.1721]]],\n",
       "\n",
       "\n",
       "        [[[0.5491, 0.3465, 0.3457, 0.4364, 0.8697],\n",
       "          [0.6266, 0.7121, 0.1769, 0.8595, 0.3286],\n",
       "          [0.4796, 0.2790, 0.2428, 0.3188, 0.6214],\n",
       "          [0.5538, 0.8634, 0.5635, 0.0851, 0.4550],\n",
       "          [0.8510, 0.6336, 0.4438, 0.8480, 0.9399]],\n",
       "\n",
       "         [[0.4484, 0.5607, 0.9066, 0.1234, 0.3238],\n",
       "          [0.3256, 0.7195, 0.9038, 0.8447, 0.7899],\n",
       "          [0.0900, 0.9005, 0.5042, 0.4565, 0.1681],\n",
       "          [0.9122, 0.5243, 0.1330, 0.9190, 0.9864],\n",
       "          [0.6452, 0.3244, 0.7616, 0.3307, 0.9264]],\n",
       "\n",
       "         [[0.7736, 0.3248, 0.4871, 0.2052, 0.0907],\n",
       "          [0.3416, 0.0877, 0.6202, 0.8402, 0.0045],\n",
       "          [0.3616, 0.2961, 0.5983, 0.7305, 0.3795],\n",
       "          [0.0235, 0.6179, 0.7853, 0.2034, 0.5058],\n",
       "          [0.9474, 0.9497, 0.9409, 0.6376, 0.1302]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t = torch.rand(2, 3, 5, 5) # форма [батч, каналы, строки, столбцы]\n",
    "batch_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b4117",
   "metadata": {},
   "source": [
    "Иногда каналы размещаются в измерении 0, а иногда - в измерении 1.\n",
    "Но обобщение можно производить путем отсчета с конца: они всегда расположены в -3 с конца.\n",
    "\n",
    "Вычисление невзвешенного среднего можно записать следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b5a6153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_navie = img_t.mean(-3)\n",
    "batch_gray_navie = batch_t.mean(-3)\n",
    "\n",
    "img_gray_navie.shape, batch_gray_navie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed885824",
   "metadata": {},
   "source": [
    "### Работа с атрибутом dtype тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99efbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ef230da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64) \n",
      "\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "print(double_points, '\\n')\n",
    "print(short_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19780fb",
   "metadata": {},
   "source": [
    "Получить информацию о dtype тензора можно путем обращения к ссответствующему атрибуту:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b0e0e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_points.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1ee8b",
   "metadata": {},
   "source": [
    "Можно также привести результат ф-ции создания тензора к нужному типу с помощью соответствующего метода приведения типов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d50050c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582e5d6",
   "metadata": {},
   "source": [
    "Или более удобного метода to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84650fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "short_points = torch.ones(10, 2).to(torch.short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae983d",
   "metadata": {},
   "source": [
    "**\"За кулисами\"** to проверяет необходимость преобразования и производит его, если нужно.\n",
    "\n",
    "Методы приведения типов dtype например float, являются сокращенными формамим вызова метода to, но они могут также принимать дополнительные аргументы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76f281",
   "metadata": {},
   "source": [
    "**ПРИ СМЕШИВАНИИ ВХОДНЫХ ТИПОВ ДАННЫХ В ОПЕРАЦИЯХ ДАННЫЕ АВТОМАТИЧЕСКИ ПРЕОБРАЗУЮТСЯ К БОЛЬШЕМУ ТИПУ.** Следовательно, если нам нужны 32-битные вычисления, нужно убедится, что все входные сигналы (как минимум) 32-битные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b13c88",
   "metadata": {},
   "source": [
    "***\n",
    "### Операции над тензорами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b33437",
   "metadata": {},
   "source": [
    "Лучше смотреть в доке: [клик](https://pytorch.org/docs/stable/tensors.html)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88a776",
   "metadata": {},
   "source": [
    "## Тензоры: Хранение в памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21d8ce",
   "metadata": {},
   "source": [
    "Память под значения в тензорах выделяется непрерывными фрагментами под управлением экземпляров **torch.Storage**. Хранилище предстовляет собой одномерный массив числовыхх данных, то есть непрерывный фрагмент в памяти, содержащий числа заданного типа. Экземпляр класса **Tensor Pytorch** - это представление подобного экземпляра **Storage** с возможностью доступа к хранилищу по индексу через указание сдвига и шага по каждому измерению.\n",
    "\n",
    "**Несколько тензоров могут обращаться к одному хранилищу, даже если индексация данных происходит по разному.**\n",
    "\n",
    "Лежащая в основе тензора память выделяется только один раз, благодаря чему создание различных тензорных представлений данных происходит очень быстро вне зависимости от размера данных, контролируемых экземпляром **Storage**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aac3cc",
   "metadata": {},
   "source": [
    "## Доступ к хранилищу по индексу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed452986",
   "metadata": {},
   "source": [
    "Обращаться к конкретному хранилищу тензора можно посредством его свойств **.storage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9c8107a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e258094",
   "metadata": {},
   "source": [
    "И хотя тензор сообщает, что содержит три строки и два столбца, лежащее в его основе хранилище представляет собой непрерывный массив размером 6. В этом смысле тензор просто знает, как преобразовать пару индексов в место в этом хранилище.\n",
    "\n",
    "Мы не сможем обращаться по индексу к хранилищу двумерного тензора с помощью двух индексов. Хранилище всегда представляет собой одномерный массив вне зависимости от размерности каких-либо ссылающихся на него тензоров.\n",
    "\n",
    "Теперь нас наврятли удивит, что изменение значения в хранилище приводит к изменению содержимого тензора,который на него ссылается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f6165cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]])\n",
    "points_storage = points.storage()\n",
    "points_storage[0] = 2.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563c714",
   "metadata": {},
   "source": [
    "### Модификация хранимых значений: операции с заменой на месте"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce116ef",
   "metadata": {},
   "source": [
    "Помимо представленных в предыдущем разделе операций над тензорами, небольшое кол-во операций доступно только в виде методов объекта **Tensor**. Их можно отличить по подчеркиванию в конце названия, как в zero_, указывающему, что метод работает с заменой на месте (in place), изменяя входные данные вместо того, чтобы создавать новый выходной тензор и возвращать его. Например, метод zero_ обнуляет все элементы входного тензора. \n",
    "\n",
    "Все методы, **в конце названия которых НЕТ символов подчеркивания**, оставляют исходный тензор неизменным и вместо этого возвращают новый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "427d1225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a.zero_()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6df8d",
   "metadata": {},
   "source": [
    "***\n",
    "## Метаданные тензоров: размер, сдвиг и шаг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93126d9c",
   "metadata": {},
   "source": [
    "Для доступа к хранилищу по индексу в тензорах используется несколько элементов информации, которые вместе с хранилищем однозначно определяют их: размер, сдвиг, шаг. Размер (форма в NumPy) представляет собой кортеж, содержащий число элементов тензора по каждому измерению. \n",
    "\n",
    "Сдвиг хранилища - это индекс в хранилище, соответствующий первому элементу тензора.\n",
    "\n",
    "Шаг - это кол-во элементов хранилища, пропускаемых между последовательными элементами по каждому измерению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591a619",
   "metadata": {},
   "source": [
    "### Представления хранилища другого тензора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151f456",
   "metadata": {},
   "source": [
    "Мы можем получить вторую точку из тензора, указав соответствующий индекс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a09d7688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]], [[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]]])\n",
    "second_point = points[1]\n",
    "second_point.storage_offset() # Возвращает смещение элемента тензора и первого элемента хранения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9cd0504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10d707",
   "metadata": {},
   "source": [
    "Сдвиг полученного в результате тензора в хранилище равен 2 (поскольку мы пропускаем первую точку, содержащую два элемента), а размер представляет собой экземпляр класса **Size**, содержащий один элемент, поскольку наш тензор одномерный.\n",
    "\n",
    "Шаг представляет собой кортеж, указывающий в себе число элементов в хранилище, пропускаемое при увеличении индекса на 1 по каждому измерению. Например, шаг тензора **points** равен (2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a538221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]],\n",
       "\n",
       "        [[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2572386a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 12]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81157cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53c6eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1062f8",
   "metadata": {},
   "source": [
    "Доступ по индексу производится к тому же хранилищу, что и у исходного тензора **points**. А это значит, что побочным эффектом изменения подтензора станет изменение исходного тензора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b4f26bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da361e",
   "metadata": {},
   "source": [
    "Такое поведение не всегда желательно, так что имеет смысл перезаписать наш подтензор в новый тензор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8dd42868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]])\n",
    "second_point = points[1].clone()\n",
    "second_point[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a23dbd",
   "metadata": {},
   "source": [
    "## Транспонирование без копирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4000d4b6",
   "metadata": {},
   "source": [
    "Попробуем теперь транспонировать тензор. Возьмем наш тензор **points**, в котором отдельные точки отсчитываются по строкам, а координаты x и y - по столбцам, и транспонируем его, чтобы отдельные точки отсчитывались по столбцам. Воспользуемся этим случаем , чтобы познакомить вас с функцией **t** - сокращенной записью ф-ции **transpose** для двумерных тензоров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4dfbc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcaf33ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a1415",
   "metadata": {},
   "source": [
    "Можно легко убедится, что **хранилище у этих двух тензоров одно**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c65d6c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage()) == id(points_t.storage())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976370a9",
   "metadata": {},
   "source": [
    "И что они отличаются только формой и шагом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e632263e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e82eaf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70a8b6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab748c53",
   "metadata": {},
   "source": [
    "### Транспонирование при более высокой размерности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de696dd5",
   "metadata": {},
   "source": [
    "Транспонировать в Pytorch можно не только матрицы. Можно транспонировать многомерный массив, и для этого достаточно указать два измерения, по которым нужно произвести транспонирование (зеркально отражая форму и шаг):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41068914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "transpose_t = some_t.transpose(0,2)\n",
    "some_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "439651cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4227c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a2a340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17855b3e",
   "metadata": {},
   "source": [
    "Непрерывные тензоры удобны тем, что их можно эффективно просматривать по порядку, не прыгая по хранилищу от одного элемента к другому (улучшение лояльности данных повышает производительность благодаря тому, как происходит доступ к памяти в современных CPU). Конечно это зависит от способа выполнения алгоритмов обращения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25848080",
   "metadata": {},
   "source": [
    "### Непрерывные тензоры\n",
    "\n",
    "Непрерывный тензор - это тензор, элементы которого хранятся в непрерывном порядке, не оставляя пустого пространства между ними. Тензор, созданный изначально, всегда является непрерывным тензором. Тензор можно просматривать в разных измерениях непрерывным образом.\n",
    "\n",
    "**Транспонирование тензора создает представление исходного тензора, которое следует несмежному порядку. Транспонирование тензора не является непрерывным.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c066c8",
   "metadata": {},
   "source": [
    "Некоторые тензорные операции наподобие **viev**, в Pytorch работают только для непрерывных тензоров.\n",
    "\n",
    "В подобном случае PyTorch формирует информативное исключение и требует явного вызова ф-ции **contiguous**. Стоит отметить, что если тензор уже непрерывный, то никаких действий при вызове **contiguous** не производится (и на производительности это никак не сказывается)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17e0ea65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca1b9478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ff33c",
   "metadata": {},
   "source": [
    "В нашем случае тензор points непрерывный, а транспонированный к нему - нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28a6ac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d39faf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0721b",
   "metadata": {},
   "source": [
    "Получить новый непрерывный тензор из ненепрерывного можно с помощью метода **contiguous**. Содержимое этого нового тензора будет таким же, но шаг, как хранилище, изменится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8debc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]])\n",
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4af45ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7817964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb25c979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85e57a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 5.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 1.0\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82ac76a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb7d83",
   "metadata": {},
   "source": [
    "Новое хранилище было перетасованно, чтобы в новом хранилище элементы располагались построчно. Шаг также был изменен в соответствие с новым размещением элементов.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fdf14",
   "metadata": {},
   "source": [
    "## Перенос тензоров на GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b7456",
   "metadata": {},
   "source": [
    "Любой из тензоров PyTorch можно перенести на (один из) GPU системы для массово параллельных быстрых вычислений. После этого все производимые с этим тензором операции будут выполнятся с помощью специализированных процедур для работы с GPU, включенных в PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb383c",
   "metadata": {},
   "source": [
    "### работа с атрибутом device тензоров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8663cd",
   "metadata": {},
   "source": [
    "Помимо **dtype**, класс Tensor представляет атрибут **device**, который описывает, где на компьютере размещаются данные тензора. Вот как можно создать тензор в GPU, указав в конструкторе соответствующий аргумент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9d1cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375977f7",
   "metadata": {},
   "source": [
    "Вместо этого можно скопировать созданный в CPU тензор на GPU с помощью метода **to**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44b1eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fd5101",
   "metadata": {},
   "source": [
    "При этом возвращается новый тензор с теми же числовыми данными, но хранящийся в памяти GPU, а не в обычной оперативной памяти системы.\n",
    "\n",
    "\n",
    "Если на нашей машине больше одного GPU, можно также указать, на каком именно GPU размещать тензор, передав отсчитываемый с нуля целочисленный номер GPU на машине, вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ac8c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.to(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d54bb8",
   "metadata": {},
   "source": [
    "После этого все операции над тензором, например умножение всех элементов на константу, производится на GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dcccecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0,], [2.0, 1.0]])\n",
    "point = 2 * points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "535f7e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.69 s\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "point_gpu = 2 * points.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cabec",
   "metadata": {},
   "source": [
    "**ОТМЕТИМ, что тензор points_gpu не передается обратно в CPU после вычисления результата. Вот что происходит:**\n",
    "\n",
    "1. Тензор points копируется в GPU.\n",
    "2. Выделяется память в GPU под новый тензор, в котором будет хранится результат умножения.\n",
    "3. Возвращается обращение к этому GPU тензору.\n",
    "\n",
    "Следовательно, если мы прибавим к результату константу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90283a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points_gpu + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b7107",
   "metadata": {},
   "source": [
    "Операции сложения будет по-прежнему производится в GPU и никакой информации в CPU передаваться не будет (если мы не будем выводить полученный тензор на экран или обращаться к нему). Для переноса тензора обратно в CPU необходимо указать в методе to аргумент cpu, вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5bf090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_cpu = points_gpu.to(device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd881c7",
   "metadata": {},
   "source": [
    "Можно также для получения тогоже результата воспользоваться сокращенными методами cpu и cuda вместо метода to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27c8749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.cuda() # По умолчанию перекидывает на GPU с индексом 0\n",
    "points_gpu = points.cuda(0) # Явно указываем, что перекидываем на нулевую GPU\n",
    "points_cpu = points.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc131c1",
   "metadata": {},
   "source": [
    "Стоит также упомянуть, с помощью метода to можно менять тип данных и их размещение одновременно, указав в качестве аргументов device и dtype.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f4b6c9",
   "metadata": {},
   "source": [
    "## Совместимость с Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d705d9",
   "metadata": {},
   "source": [
    "Тензоры PyTorch можно очень эффективно преобразовывать в массивы NumPy и наоборот. Благодаря этому можно воспользоваться огромными объемами функциональности экосистемы Python, основанных на типах массивов NumPy.\n",
    "\n",
    "Чтобы получить массив NumPy из нашего тензора points, достаточно вызвать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "899b3f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.ones(3, 4)\n",
    "points_np = points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade26e33",
   "metadata": {},
   "source": [
    "Этот код возвращает многомерный массив NumPy нужного размера, формы и числового типа. Интересно то, что у возвращаемого массива один и тот же буфер с тензорным хранилищем. Это значит, что выполнение метода numpy практически не подразумевает накладных расходов, если данные хранятся на CPU, а также что модификация массива NumPy ведет к изменениям исходного тензора.\n",
    "\n",
    "Если память под тензор выделяется в GPU, Pytorch копирует содержимое тензора в массив NumPy, расположенный в CPU.\n",
    "\n",
    "И наоборот, вот так можно получить тензор PyTorch из массива NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28c6fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.from_numpy(points_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6d00c",
   "metadata": {},
   "source": [
    "С сохранением той же стратегии совместного использования буфера, которую мы только что описали.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354c2ee",
   "metadata": {},
   "source": [
    "## Обобщенные тензоры тоже тензоры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83cb2c",
   "metadata": {},
   "source": [
    "Pytorch вызывает правильные вычислительные ф-ции вне зависимости от того, размещен ли тензор в памяти CPU или GPU. Достигается это с помощью механизма **диспетчеризации** способного обслуживать другие типы тензоров посредством подключения API пользователя к нужным ф-циям прикладной части. Размуеется, существуют другие виды тензоров: некоторые специально предназначены для конкретных классов аппаратных устройств (например, TPU от Google), а стратегии представления данных у других массивов отличаются от плотных массивов, с которыми мы сталкивались до сих пор.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f35efb6",
   "metadata": {},
   "source": [
    "## Сериализация тензоров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b288d3",
   "metadata": {},
   "source": [
    "Создавать тензоры по ходу дела удобно, но если внутри него ценные данные, желательно сохранить его в файл и загрузить потом обратно. В конце концов, мы же не хотим обучать модель с нуля каждый раз, когда запускаем программу! Для сериализации объектов-тензоров PyTorch использует \"за кулисами\" pickle, а также специализированный код сериализации для хранилища. Вот как можно сохранить наш тензор points в файл ourpoints.t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a582c466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d28fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(points, './data/ourpoints.t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be9208",
   "metadata": {},
   "source": [
    "Либо можно передать дескриптор файла вместо его названия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d696d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ourpoints.t', 'wb') as f:\n",
    "    torch.save(points, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ab11a",
   "metadata": {},
   "source": [
    "Загрузка тензора points обратно тоже выполняется одной строкой кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b80ac5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.load('./data/ourpoints.t')\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e1a69",
   "metadata": {},
   "source": [
    "Что эквивалентно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ef566b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del points\n",
    "\n",
    "with open('./data/ourpoints.t', 'rb') as f:\n",
    "    points = torch.load(f)\n",
    "    \n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaee180",
   "metadata": {},
   "source": [
    "И хотя подобным образом можно быстро сохранять тензоры, если их нужно загружать только в PyTorch, сам по себе формат не отличается совместимостью: прочитать тензор с помощь какого-либо еще ПО, помимо PyTorch, **не получится**. В зависимости от сценария использования, это может и не ограничивать наши возможности, но в противном случае имеет смысл выяснить, как сохранять тензоры совместимым образом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da702d52",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Задания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a66a06",
   "metadata": {},
   "source": [
    "Создать тензор из list(range(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d99285ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.tensor(list(range(9)))\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c8722b",
   "metadata": {},
   "source": [
    "**view** - Возвращает новый тензор с теми же данными, что и собственный тензор, но другой формы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "92966887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4371, -0.5058, -0.6620, -1.0235,  2.9106, -0.7871,  0.3801,  1.2505,\n",
      "        -0.5998]) \n",
      "\n",
      "tensor([[-0.4371, -0.5058, -0.6620],\n",
      "        [-1.0235,  2.9106, -0.7871],\n",
      "        [ 0.3801,  1.2505, -0.5998]]) \n",
      "\n",
      "tensor([[-0.4371, -0.5058, -0.6620],\n",
      "        [-1.0235,  2.9106, -0.7871],\n",
      "        [ 0.3801,  1.2505, -0.5998]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(9)\n",
    "b = a.view(3, 3)\n",
    "z = a.view(-1, 3)\n",
    "print(a, '\\n')\n",
    "print(b, '\\n')\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e51b6948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4371, -0.5058, -0.6620],\n",
      "        [-1.0235,  2.9106, -0.7871],\n",
      "        [ 0.3801,  1.2505, -0.5998]]) \n",
      "\n",
      "tensor([[ 2.9106, -0.7871],\n",
      "        [ 1.2505, -0.5998]])\n"
     ]
    }
   ],
   "source": [
    "c = b[1:,1:]\n",
    "print(b, '\\n')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf8bae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  0.5403, -0.4161, -0.9900, -0.6536,  0.2837,  0.9602,  0.7539,\n",
       "        -0.1455])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.cos(torch.tensor(list(range(9))))\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
